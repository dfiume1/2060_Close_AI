{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvIZqWCd2L6C"
   },
   "source": [
    "# Boosting With Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to github: https://github.com/dfiume1/2060_Close_AI.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVJqYh6u2Qtz"
   },
   "source": [
    "## Markdown Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the Boosting Algorithm\n",
    "\n",
    "Boosting is an ensemble learning method. The idea of boosting algorithm is to create a single strong learner by combining the predictions of weak learners. This method was proposed by Freund and Schapire in the paper \"A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting\" in 1995 [1] and mainly applied to classification tasks. In boosting, each weak learner will adjust its weight according to the results of the previous round of weak learners in continuous iterations. Boosting iteratively builds weak classifiers or regressors and this new learner will pay special attention to the samples that were misclassified or having bigger errors in the previous round, so as to better handle these samples that did not perform well in the subsequent iterations. Thus, models can gradually optimize the performance. In the final prediction stage, the prediction results of these weak learners will be weighted and summed according to certain weights to obtain the final prediction result. Based on boosting, Freund and Schapire also proposed AdaBoosting, the adaptive boosting algorithm, in the above paper. At the same time, Drucker further applied it to regression problems in 1997. [2]\n",
    "Adaboosting improves the adaptive mechanism: Adaboosting dynamically adjusts the sample weights and the weights of weak learners according to the error during the iteration process. This adaptive mechanism enables AdaBoosting to gradually optimize the model performance and improve the prediction accuracy.\n",
    "\n",
    "### Advantages\n",
    "- According to Drucker's 1997 paper \"Improving Regressors using Boosting Techniques\", AdaBoosting can achieve higher prediction performance by iteratively training multiple weak learners and reasonably combining their prediction results according to the weights. [2]\n",
    "- The AdaBoosting algorithm is relatively simple and easy to understand and implement.\n",
    "\n",
    "### Disadvantages\n",
    "- Since AdaBoosting gives higher weights to wrongly predicted samples, noise and outliers may cause the model to perform poorly. .\n",
    "- AdaBoosting needs to train multiple weak learners during the training process, the amount of training calculations may be heavy.\n",
    "- If the weak learner is too complex or the number of iterations is too many, AdaBoosting may have overfitting problems.\n",
    "\n",
    "### Modification\n",
    "In this project, we used Adaboosting to implement regression instead of classification problems. The main changes made are as follows:\n",
    "- We chose a 1 layer NN as a weak learner because NN has strong fitting ability and is suitable as a weak learner for regression tasks.\n",
    "- We used mean squared error as the loss function instead of 0/1 loss.\n",
    "\n",
    "\n",
    "### Representation\n",
    "\n",
    "Let $H$ be the class of base, un-boosted hypotheses. Then, $E$ is defined as the ensemble of $H$ weak learners of size $T$.\n",
    "\n",
    "$$E(H, T) = {x \\to (Σ(w_t * h_t(x))) : w ∈ R^T, ∀t, h_t ∈ H}$$\n",
    "\n",
    "$h_t(x)$: Prediction result from the t-th weak learner.\n",
    "\n",
    "$w_t$ Weight of the t-th learner, determined based on its performance.\n",
    "\n",
    "T: Total number of weak learners in the ensemble.\n",
    "\n",
    "As can be seen from the above, by combining $w_t$ and $h_t(x)$, the weak learner with higher accuracy has a greater weight in the final prediction.\n",
    "\n",
    "### Loss\n",
    "\n",
    "The loss function quantifies the error between the model's predicted value and the true value, providing guidance for the optimization process.\n",
    "\n",
    "For the ensemble Hypothesis, we are using the mean square loss (mse) which is defined as:\n",
    "$$L_S(E(H, T)) = \\frac{1}{m}\\sum\\limits_{i=1}^m(y_{i}-E(H, T)({\\bf x}_{i}))^{2}$$\n",
    "\n",
    "### Optimizer\n",
    "\n",
    "The iterative optimization process of AdaBoosting mainly consists of five steps:\n",
    "\n",
    "- First, initialization is performed to assign equal weights to all training samples, where $m$ is the number of samples, $D$ is the weight distribution of each training sample, and $D^{(1)} = \\frac{1}{m}$.\n",
    "\n",
    "- Next, in each iteration, a weak learner $h_t$ is trained using the weighted dataset.\n",
    "\n",
    "- The third step is to calculate the error rate $\\epsilon_t$ of the weak learner.\n",
    "\n",
    "- The fourth step is to calculate the weight $w_t$ of the weak learner and adjust the sample weights $D_i^{(t+1)}$ to pay more attention to the misclassified samples.\n",
    "\n",
    "- Finally, we combine the predictions of all weak learners into the final integrated model.\n",
    "\n",
    "Through the flexible weight adjustment and weighted integration strategy of the prediction results during the iteration process, we can gradually improve the accuracy of the results.\n",
    "\n",
    "below is the pesudoCode:\n",
    "\n",
    "Input:\n",
    "- Training set $S = \\{(\\mathbf{x}_1, y_1), \\ldots, (\\mathbf{x}_m, y_m)\\}$\n",
    "- Weak learner $Wl$\n",
    "- Number of estimators $T$\n",
    "\n",
    "Initialize:\n",
    "$D^{(1)} = \\left(\\frac{1}{m}, \\ldots, \\frac{1}{m}\\right)$\n",
    "\n",
    "For $t = 1, \\ldots, T$:\n",
    "\n",
    "$h_t = WL(D^{(t)}, S)$\n",
    "\n",
    "$\\epsilon_t = \\sum_{i=1}^m D_i^{(t)} (y_i - h_t(\\mathbf{x_i}))^2$\n",
    "\n",
    "$w_t = \\frac{1}{2} \\log \\left(\\frac{1 - \\epsilon_t}{\\epsilon_t}\\right)$\n",
    "\n",
    "$D_i^{(t+1)} = \\frac{D_i^{(t)} \\exp(-w_t y_i h_t(\\mathbf{x}_i))}{\\sum_{j=1}^m D_j^{(t)} \\exp(-w_t y_j h_t(\\mathbf{x}_j))} \\quad \\forall i = 1, \\ldots, m$\n",
    "\n",
    "Output:\n",
    "- The hypothesis: $h_S(\\mathbf{x}) = \\sum_{t=1}^T w_t h_t(\\mathbf{x})$\n",
    "\n",
    "### Weak Learner\n",
    "Typically a simple learning model that performs slightly better than random guessing, with limited results. We decided to see if we could improve the performance of a One Layer Neural Network (even though it is a \"strong\" learner in general). \n",
    "\n",
    "#### Representation\n",
    "-  The representation of One Layer Neural Network is below, which is equivalent to linear regression:\n",
    "$$h({\\bf x}) = \\langle {\\bf w},  {\\bf x}\\rangle+ b.$$\n",
    "\n",
    "- We then add data weighted learning capabilites to the model (i.e. we can tell the model how important a piece of data is.)\n",
    "\n",
    "$$h({\\bf x_i}) = D_i \\langle {\\bf w},  {\\bf x_i}\\rangle+ b.$$\n",
    "\n",
    "Where $D_i$ is the ith data weight.\n",
    "\n",
    "#### Loss\n",
    "We are using weighted L2 loss for the one-layer neural network and MSE for the boosted ensemble of hypotheses.\n",
    "- For each single-layer neural network, loss is defined as:\n",
    "$$L_S(h_{\\bf t}) = \\sum\\limits_{i=1}^m w_i*(y_{i}-h_{\\bf t}({\\bf x}_{i}))^{2}$$\n",
    "\n",
    "where *y*<sub>i</sub> is the target value of *i*<sup>th</sup>\n",
    "sample\n",
    "\n",
    "$h_{\\bf t}({\\bf x})$ is the predicted value of that\n",
    "sample given the learned model weights\n",
    "\n",
    "$w_m$ is the weight for the mth data point.\n",
    "\n",
    "#### Optimizer\n",
    "By using Stochastic Gradient Descent as the optimizer, our one-layer neural network can gradually update the weights and biases to optimize the loss function. \n",
    "\n",
    "$\\frac{\\partial L_i}{\\partial \\mathbf{W}} = (\\hat{y}_i - y_i) \\mathbf{x}_i$\n",
    "\n",
    "$\\frac{\\partial L_i}{\\partial b} = \\hat{y}_i - y_i$\n",
    "\n",
    "$\\mathbf{W}_{t+1} = \\mathbf{W}_t - \\eta \\frac{\\partial L_i}{\\partial \\mathbf{W}}$\n",
    "\n",
    "$b_{t+1} = b_t - \\eta \\frac{\\partial L_i}{\\partial b}$\n",
    "\n",
    "$\\hat{y}_i = f(\\mathbf{W}^\\top \\mathbf{x}_i + b)$\n",
    "\n",
    "where: \n",
    "\n",
    "w: Weights of the model\n",
    "\n",
    "b: Bias \n",
    "\n",
    "η: Learning rate\n",
    "\n",
    "$y_i$: Target value\n",
    "\n",
    "$y^i$: Predicted results\n",
    "\n",
    "$l_i$: Loss for the i-th datapoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUF8LgSz3Nna"
   },
   "source": [
    "### Check Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHKoyt0u2tiR",
    "outputId": "357f42eb-bd03-4dcb-a75b-cd289e2a5cb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m[ OK ]\u001b[0m Python version is 3.12.5\n",
      "\n",
      "\u001b[42m[ OK ]\u001b[0m matplotlib version 3.9.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m numpy version 2.0.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m sklearn version 1.5.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m pandas version 2.2.2 is installed.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from packaging.version import parse as Version\n",
    "from platform import python_version\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.12.5 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == Version(min_ver):\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))\n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(python_version())\n",
    "\n",
    "if pyversion >= Version(\"3.12.5\"):\n",
    "    print(OK, \"Python version is %s\" % pyversion)\n",
    "elif pyversion < Version(\"3.12.5\"):\n",
    "    print(FAIL, \"Python version 3.12.5 is required,\"\n",
    "                \" but %s is installed.\" % pyversion)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % pyversion)\n",
    "\n",
    "\n",
    "print()\n",
    "requirements = {'matplotlib': \"3.9.1\", 'numpy': \"2.0.1\",'sklearn': \"1.5.1\",\n",
    "                'pandas': \"2.2.2\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfCnqsOY3WLp"
   },
   "source": [
    "## Model Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5npX8gMU3Y0I"
   },
   "source": [
    "### Weak Learner: One Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dFNBypLJ1nJY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def l2_loss_weight(predictions,Y,weights):\n",
    "    '''\n",
    "        Computes L2 loss (sum squared loss) between true values, Y, and predictions.\n",
    "        that are weighted\n",
    "        :param Y: A 1D Numpy array with real values (float64)\n",
    "        :param predictions: A 1D Numpy array of the same size of Y\n",
    "        :param weights: A 1D Numpy array of the same size of Y,\n",
    "        :return: Weighted L2 loss using predictions for Y.\n",
    "    '''\n",
    "\n",
    "    return np.sum(weights * (predictions - Y)**2)\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class OneLayerNN(BaseEstimator, RegressorMixin):\n",
    "    '''\n",
    "        One layer neural network trained with Stocastic Gradient Descent (SGD)\n",
    "    '''\n",
    "    def __init__(self, learning_rate = 0.001, num_epochs = 25, batch_size = 1):\n",
    "        '''\n",
    "        @attrs:\n",
    "            weights: The weights of the neural network model.\n",
    "            batch_size: The number of examples in each batch\n",
    "            learning_rate: The learning rate to use for SGD\n",
    "            epochs: The number of times to pass through the dataset\n",
    "            v: The resulting predictions computed during the forward pass\n",
    "        '''\n",
    "        # initialize self.weights in fit()\n",
    "        self.weights = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # initialize self.v in forward_pass()\n",
    "        self.v = None\n",
    "        self.data_weights = None\n",
    "    \n",
    "    def fit(self, X, Y, data_weights=None):\n",
    "        '''\n",
    "        Trains the OneLayerNN model using SGD.\n",
    "        :param X: 2D Numpy array where each row contains an example\n",
    "        :param Y: 1D Numpy array containing the corresponding values for each example\n",
    "        :param print_loss: If True, print the loss after each epoch.\n",
    "        :return: None\n",
    "        '''\n",
    "        # initialize weights\n",
    "        num_examples, num_features = X.shape\n",
    "        self.weights = np.random.uniform(0, 1, (1, num_features))\n",
    "        if data_weights is None:\n",
    "            self.data_weights = np.ones(num_examples)\n",
    "        else:\n",
    "            self.data_weights = data_weights / max(data_weights)\n",
    "        # Train network for certain number of epochs\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # Shuffle the examples (X) and labels (Y)\n",
    "            indices = np.random.permutation(num_examples)\n",
    "            X_shuffled = X[indices]\n",
    "            Y_shuffled = Y[indices]\n",
    "            data_weights_shuffled = self.data_weights[indices]\n",
    "        # iterate through the examples in batch size increments\n",
    "            for i in range(num_examples):\n",
    "\n",
    "                x_i = X_shuffled[i].reshape(1, num_features)\n",
    "                y_i = Y_shuffled[i].reshape(1, 1)            \n",
    "                data_i = data_weights_shuffled[i]\n",
    "                # Perform the forward and backward pass on the current batch\n",
    "                self.forward_pass(x_i)\n",
    "                self.backward_pass(x_i, y_i, data_i)\n",
    "\n",
    "            # Print the loss after every epoch\n",
    "            # if print_loss:\n",
    "            #     print('Epoch: {} | Loss: {}'.format(epoch, self.loss(X, Y)))\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        '''\n",
    "        Computes the predictions for a single layer given examples X and\n",
    "        stores them in self.v\n",
    "        :param X: 2D Numpy array where each row contains an example.\n",
    "        :return: None\n",
    "        '''\n",
    "        self.v = np.dot(self.weights, X.T).flatten()\n",
    "\n",
    "    def backward_pass(self, X, Y, data_weights):\n",
    "        '''\n",
    "        Computes the weights gradient and updates self.weights\n",
    "        :param X: 2D Numpy array where each row contains an example\n",
    "        :param Y: 1D Numpy array containing the corresponding values for each example\n",
    "        :return: None\n",
    "        '''\n",
    "        # Compute the gradients for the model's weights using backprop\n",
    "        gradient = self.backprop(X, Y, data_weights)\n",
    "        # Update the weights using gradient descent\n",
    "        self.gradient_descent(gradient)\n",
    "\n",
    "    def backprop(self, X, Y, data_weights):\n",
    "        '''\n",
    "        Returns the average weights gradient for the given batch\n",
    "        :param X: 2D Numpy array where each row contains an example.\n",
    "        :param Y: 1D Numpy array containing the corresponding values for each example\n",
    "        :return: A 1D Numpy array representing the weights gradient\n",
    "        '''\n",
    "        # Compute the average weights gradient\n",
    "        loss = self.v - Y\n",
    "        return np.dot(2*loss*data_weights, X)\n",
    "\n",
    "    def gradient_descent(self, grad_W):\n",
    "        '''\n",
    "        Updates the weights using the given gradient\n",
    "        :param grad_W: A 1D Numpy array representing the weights gradient\n",
    "        :return: None\n",
    "        '''\n",
    "        self.weights -= (self.learning_rate * grad_W)\n",
    "\n",
    "    def loss(self, X, Y, data_weights):\n",
    "        '''\n",
    "        Returns the total squared error on some dataset (X, Y).\n",
    "        :param X: 2D Numpy array where each row contains an example\n",
    "        :param Y: 1D Numpy array containing the corresponding values for each example\n",
    "        :return: A float which is the squared error of the model on the dataset\n",
    "        '''\n",
    "        # Perform the forward pass and compute the l2 loss\n",
    "        self.forward_pass(X)\n",
    "        return l2_loss_weight(self.v, Y, data_weights)\n",
    "\n",
    "    def average_loss(self, X, Y, data_weights):\n",
    "        '''\n",
    "        Returns the mean squared error on some dataset (X, Y).\n",
    "        MSE = Total squared error/# of examples\n",
    "        :param X: 2D Numpy array where each row contains an example\n",
    "        :param Y: 1D Numpy array containing the corresponding values for each example\n",
    "        :return: A float which is the mean squared error of the model on the dataset\n",
    "        '''\n",
    "        return self.loss(X, Y, data_weights) / X.shape[0]\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "            Returns the predicted values for some dataset (X).\n",
    "            :param X: 2D Numpy array where each row contains an example\n",
    "            :return: 1D Numpy array containing the predicted values for each example\n",
    "        '''\n",
    "        self.forward_pass(X)\n",
    "        return self.v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JW3JqPeK3hVC"
   },
   "source": [
    "### Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eDK23Q7F3gZJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Boosted_Model:\n",
    "  def __init__(self, n_estimators=50, learning_rate=0.5, random_state=1):\n",
    "    self.n_estimators = n_estimators\n",
    "    self.learning_rate = learning_rate\n",
    "    self.random_state = random_state\n",
    "    self.estimator_weights = np.zeros(self.n_estimators)\n",
    "    self.data_weights = []\n",
    "\n",
    "    # Initialize the estimators\n",
    "    self.estimators = []\n",
    "    for i in range(self.n_estimators):\n",
    "      self.estimators.append(OneLayerNN())\n",
    "      \n",
    "\n",
    "  def train(self, X, y):\n",
    "    '''\n",
    "    Trains/Fits the Boosting Model using AdaBoost.\n",
    "    :param X: 2D Numpy array where each row contains an example\n",
    "    :param Y: 1D Numpy array containing the corresponding values for each example\n",
    "    '''\n",
    "    # Initialize the data and estimator weights\n",
    "    num_inputs = X.shape[0]\n",
    "    self.data_weights = np.ones(num_inputs) / num_inputs\n",
    "\n",
    "    # For each round/weak learner\n",
    "    for i in range(self.n_estimators):\n",
    "\n",
    "      # Use the weak learner\n",
    "      weak_learner = self.estimators[i]\n",
    "\n",
    "      # Fit the weak learner\n",
    "      weak_learner.fit(X, y, self.data_weights)\n",
    "      # print(self.data_weights)\n",
    "      #print(\"Before Reshape\", weak_learner.predict(X).shape)\n",
    "      y_pred = weak_learner.predict(X).reshape(num_inputs)\n",
    "      #print(\"y_pred\", y_pred)\n",
    "\n",
    "      e_t = np.sum(self.data_weights * ((y-y_pred) ** 2)) / np.sum(self.data_weights)\n",
    "      #print(e_t)\n",
    "      e_t = np.clip(e_t, 1e-10, 0.49)\n",
    "      \n",
    "      #e_t = e_t / num_inputs\n",
    "      #print(\"weighted error\", e_t)\n",
    "      \n",
    "      w_t = 0.5 * np.log((1 - e_t) / e_t)\n",
    "      #print(\"w_t\", w_t)\n",
    "\n",
    "      self.estimator_weights[i] = w_t\n",
    "  \n",
    "      self.data_weights *= np.exp(-w_t * ((y-y_pred) ** 2))\n",
    "      self.data_weights = np.clip(self.data_weights, a_min=1e-10, a_max=1e2)\n",
    "      self.data_weights /= np.sum(self.data_weights)\n",
    "      #print(self.data_weights)\n",
    "      #print(f\"Sum of data weights (should be 1): {np.sum(self.data_weights)}\")  \n",
    "    \n",
    "    self.estimator_weights /= np.sum(self.estimator_weights)\n",
    "    #print(self.estimator_weights)\n",
    "\n",
    "\n",
    "  def loss(self, X, Y):\n",
    "      # Get predictions from all learners, then weight them\n",
    "      #print(\"Shape of Y\", Y.shape)\n",
    "      #print(\"one prediction\", self.estimators[0].predict(X).shape)\n",
    "      predictions = np.array([e.predict(X).reshape(-1) for e in self.estimators])\n",
    "      #print(\"prediction shape\", predictions.shape)\n",
    "      #predictions = predictions.reshape(self.n_estimators, Y.shape[0])\n",
    "      #print(\"prediction shape\", predictions.shape)\n",
    "      #print(\"Original Pred\", predictions)\n",
    "      #print(\"Estimator Weights\", self.estimator_weights)\n",
    "      weighted_predictions = np.dot(self.estimator_weights, predictions)\n",
    "      #print(\"Weighted\", weighted_predictions)\n",
    "      #print(Y)\n",
    "      # L2 loss\n",
    "      loss = np.mean((Y - weighted_predictions) ** 2)\n",
    "      return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Testing 1-Layer NN Gradients-----\n",
      "\n",
      "Testing layer one weights gradient.\n",
      "Layer one weights gradient is correct.\n",
      "\n",
      "----Testing 1-Layer NN with Data Weights-----\n",
      "Weights 1 [0.  0.1 0.2 0.3 0.4]\n",
      "Weights 2: [0 0 0 0 1]\n",
      "Layer one weights gradient with weighted data is correct.\n",
      "\n",
      "----Testing Weighted Loss Function -----\n",
      "Weighted Loss Function is Correct.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "# Sets random seed for testing purposes\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def test_OneLayerNN():\n",
    "    '''\n",
    "    Tests for OneLayerNN Model Weights Gradient\n",
    "    '''\n",
    "\n",
    "    test_model = OneLayerNN()\n",
    "\n",
    "    # Creates Test Data\n",
    "    x_bias = np.array([[0,4,1], [0,3,1], [5,0,1], [4,1,1], [0,5,1]])\n",
    "    y = np.array([0,0,1,1,0])\n",
    "\n",
    "    # Tests the functionality with no weights (this is the same unit test from the HW)\n",
    "    no_weights = np.array([1, 1, 1, 1, 1])\n",
    "\n",
    "    # Test Model Train \n",
    "    test_model.fit(x_bias, y, no_weights)\n",
    "\n",
    "    act_weights = test_model.weights\n",
    "    exp_weights = np.array([[ 0.17817953, -0.03543112,  0.34761945]])\n",
    "\n",
    "    print('----Testing 1-Layer NN Gradients-----')\n",
    "\n",
    "    print(\"\\nTesting layer one weights gradient.\")\n",
    "    \n",
    "    # Test layer 1 weights\n",
    "    if not hasattr(act_weights, \"shape\"):\n",
    "        print(\"Layer one weights gradient is not a numpy array. \\n\")\n",
    "    elif act_weights.shape != (1, 3):\n",
    "        print(\n",
    "            f\"Incorrect shape for layer one weights gradient.\\nExpected: {(1, 3)} \\nActual: {act_weights.shape} \\n\")\n",
    "    elif not act_weights == pytest.approx(exp_weights, .01):\n",
    "        print(\n",
    "            f\"Incorrect values for layer one weights gradient.\\nExpected: {exp_weights} \\nActual: {act_weights} \\n\")\n",
    "    else:\n",
    "        print(\"Layer one weights gradient is correct.\\n\")\n",
    "\n",
    "    print('----Testing 1-Layer NN with Data Weights-----')\n",
    "\n",
    "    # Tests the same functionality but passes in different weights. Weights 1 has different weights\n",
    "    # for each data point, while weights 2 is an edge case where there's only one data point that matters\n",
    "    data_weights_1 = np.array([0, 0.1, 0.2, 0.3, 0.4])\n",
    "    data_weights_2 = np.array([0, 0, 0, 0, 1])\n",
    "\n",
    "    print(\"Weights 1\", data_weights_1)\n",
    "    print(\"Weights 2:\", data_weights_2)\n",
    "\n",
    "    test_model1 = OneLayerNN(num_epochs=2)\n",
    "    test_model2 = OneLayerNN(num_epochs=2)\n",
    "    \n",
    "    # Test Model Train \n",
    "\n",
    "    test_model1.fit(x_bias, y, data_weights_1)\n",
    "    test_model2.fit(x_bias, y, data_weights_2)\n",
    "\n",
    "    act_weights1 = test_model1.weights\n",
    "    act_weights2 = test_model2.weights\n",
    "    \n",
    "    exp_weights1 = np.array([[0.87395, 0.583062, -0.018167]])\n",
    "    exp_weights2 = np.array([[0.9767610, 0.5315327, 0.7246010]])\n",
    "\n",
    "    if not hasattr(act_weights, \"shape\"):\n",
    "        print(\"Layer one weights gradient is not a numpy array. \\n\")\n",
    "    elif act_weights.shape != (1, 3):\n",
    "        print(\n",
    "            f\"Incorrect shape for layer one weights gradient for data weights 1.\\nExpected: {(1, 3)} \\nActual: {act_weights.shape} \\n\")\n",
    "    elif not act_weights1 == pytest.approx(exp_weights1, .01):\n",
    "        print(\n",
    "            f\"Incorrect values for data weights 1 weights gradient.\\nExpected: {exp_weights1} \\nActual: {act_weights1} \\n\")\n",
    "    elif not act_weights2 == pytest.approx(exp_weights2, .01):\n",
    "        print(\n",
    "            f\"Incorrect values for data weights 2 weights gradient.\\nExpected: {exp_weights2} \\nActual: {act_weights2} \\n\")\n",
    "    else:\n",
    "        print(\"Layer one weights gradient with weighted data is correct.\\n\")\n",
    "\n",
    "    print('----Testing Weighted Loss Function -----')\n",
    "\n",
    "    # These tests test that the weighted loss function is working properly for the provided \n",
    "\n",
    "    test_x = np.array([[0,2,1], [1,3,1], [4,2,1], [1,5,1], [0,1,1]])\n",
    "    test_y = np.array([0,1,1,0,1])\n",
    "\n",
    "    loss_normal = test_model.loss(test_x, test_y, no_weights)\n",
    "    loss1 = test_model1.loss(test_x, test_y, data_weights_1)\n",
    "    loss2 = test_model2.loss(test_x, test_y, data_weights_2)\n",
    "\n",
    "    exp_ln = 1\n",
    "    exp_loss1 = 7.25\n",
    "    exp_loss2 = 0.0656\n",
    "\n",
    "    if not loss_normal == pytest.approx(exp_ln, .01):\n",
    "        print(\n",
    "            f\"Incorrect values for mo weights loss function.\\nExpected: {exp_ln} \\nActual: {loss_normal} \\n\")\n",
    "    elif not loss1 == pytest.approx(exp_loss1, .01):\n",
    "        print(\n",
    "            f\"Incorrect values for loss with weights.\\nExpected: {exp_loss1} \\nActual: {loss1} \\n\")\n",
    "    elif not loss2 == pytest.approx(exp_loss2, .01):\n",
    "        print(\n",
    "            f\"Incorrect values for loss with weights .\\nExpected: {exp_loss2} \\nActual: {loss2} \\n\")\n",
    "    else:\n",
    "        print(\"Weighted Loss Function is Correct.\\n\")\n",
    "\n",
    "test_OneLayerNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Testing for Boosted_NN Model-----\n",
      "\n",
      "Testing with standard test case.\n",
      "Model computed loss is correct.\n",
      "Model estimator weights are correct\n",
      "\n",
      "Testing estimator weights normalization.\n",
      "Estimator weights are normalized correctly.\n",
      "\n",
      "Testing individual estimator predictions.\n",
      "Weak learner predictions shape is correct.\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Testing with a single data point.\n",
      "Model computed loss is correct.\n",
      "\n",
      "Testing estimator weights normalization.\n",
      "Estimator weights are normalized correctly.\n",
      "\n",
      "Testing individual estimator predictions.\n",
      "Weak learner predictions shape is correct.\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Testing with identical input values.\n",
      "Model computed loss is correct.\n",
      "\n",
      "Testing estimator weights normalization.\n",
      "Estimator weights are normalized correctly.\n",
      "\n",
      "Testing individual estimator predictions.\n",
      "Weak learner predictions shape is correct.\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Testing with all labels being the same.\n",
      "Model computed loss is NOT correct.\n",
      "\n",
      "Testing estimator weights normalization.\n",
      "Estimator weights are normalized correctly.\n",
      "\n",
      "Testing individual estimator predictions.\n",
      "Weak learner predictions shape is correct.\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Testing with high-dimensional input.\n",
      "Model computed loss is correct.\n",
      "\n",
      "Testing estimator weights normalization.\n",
      "Estimator weights are normalized correctly.\n",
      "\n",
      "Testing individual estimator predictions.\n",
      "Weak learner predictions shape is correct.\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Testing with a very large dataset.\n",
      "Model computed loss is correct.\n",
      "\n",
      "Testing estimator weights normalization.\n",
      "Estimator weights are normalized correctly.\n",
      "\n",
      "Testing individual estimator predictions.\n",
      "Weak learner predictions shape is correct.\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Testing with edge inputs (all zeros and ones).\n",
      "Model computed loss is correct.\n",
      "\n",
      "Testing estimator weights normalization.\n",
      "Estimator weights are normalized correctly.\n",
      "\n",
      "Testing individual estimator predictions.\n",
      "Weak learner predictions shape is correct.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_Boosted_NN():\n",
    "\n",
    "    print('-----Testing for Boosted_NN Model-----')\n",
    "\n",
    "    np.random.seed(4)\n",
    "    random.seed(4)\n",
    "\n",
    "    # Standard Test Case\n",
    "    print(\"\\nTesting with standard test case.\")\n",
    "    boosted_model = Boosted_Model(n_estimators=10, learning_rate=0.1, random_state=0)\n",
    "    X_test = np.array([[0, 4, 1], [0, 3, 1], [5, 0, 1], [4, 1, 1], [0, 5, 1]])\n",
    "    Y_test = np.array([0, 0, 1, 1, 0])\n",
    "    boosted_model.train(X_test, Y_test)\n",
    "    computed_loss = boosted_model.loss(X_test, Y_test)\n",
    "    if computed_loss == pytest.approx(0.02263503, .01):\n",
    "        print(\"Model computed loss is correct.\")\n",
    "    else:\n",
    "        print(\"Model computed loss is NOT correct.\")\n",
    "    \n",
    "    expected_weights = [0.07516408, 0.10241473, 0.09759651, 0.14614814, 0.1304729, 0.07476268, 0.08483431, 0.07745124, 0.06164749, 0.14950792]\n",
    "    if boosted_model.estimator_weights == pytest.approx(expected_weights, 0.01):\n",
    "        print(\"Model estimator weights are correct\")\n",
    "    else:\n",
    "        print(\"Model estimator weights are NOT correct\")\n",
    "\n",
    "    # Estimator Weights Normalization\n",
    "    print(\"\\nTesting estimator weights normalization.\")\n",
    "    weight_sum = np.sum(boosted_model.estimator_weights)\n",
    "    if not np.isclose(weight_sum, 1.0, atol=1e-6):\n",
    "        print(f\"Estimator weights are not normalized.\\nSum of weights: {weight_sum}\")\n",
    "    else:\n",
    "        print(\"Estimator weights are normalized correctly.\")\n",
    "\n",
    "    # Individual Estimator Predictions\n",
    "    print(\"\\nTesting individual estimator predictions.\")\n",
    "    weak_predictions = []\n",
    "    for estimator in boosted_model.estimators:\n",
    "        pred = estimator.predict(X_test).reshape(-1)\n",
    "        weak_predictions.append(pred)\n",
    "    weak_predictions = np.array(weak_predictions)\n",
    "\n",
    "    if weak_predictions.shape != (boosted_model.n_estimators, X_test.shape[0]):\n",
    "        print(f\"Incorrect shape for weak learner predictions.\\nExpected: {(boosted_model.n_estimators, X_test.shape[0])}\\n\"\n",
    "              f\"Actual: {weak_predictions.shape}\")\n",
    "    else:\n",
    "        print(\"Weak learner predictions shape is correct.\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Edge Case 1: Single Data Point\n",
    "    print(\"\\n---------------------------------\")\n",
    "    print(\"\\nTesting with a single data point.\")\n",
    "    X_test_single = np.array([[0, 0, 0]])\n",
    "    Y_test_single = np.array([1])\n",
    "    boosted_model.train(X_test_single, Y_test_single)\n",
    "    computed_loss_single = boosted_model.loss(X_test_single, Y_test_single)\n",
    "    if computed_loss_single == 1.0:\n",
    "        print(\"Model computed loss is correct.\")\n",
    "    else:\n",
    "        print(\"Model computed loss is NOT correct.\")\n",
    "    # Estimator Weights Normalization\n",
    "    print(\"\\nTesting estimator weights normalization.\")\n",
    "    weight_sum = np.sum(boosted_model.estimator_weights)\n",
    "    if not np.isclose(weight_sum, 1.0, atol=1e-6):\n",
    "        print(f\"Estimator weights are not normalized.\\nSum of weights: {weight_sum}\")\n",
    "    else:\n",
    "        print(\"Estimator weights are normalized correctly.\")\n",
    "\n",
    "    # Individual Estimator Predictions\n",
    "    print(\"\\nTesting individual estimator predictions.\")\n",
    "    weak_predictions = []\n",
    "    for estimator in boosted_model.estimators:\n",
    "        pred = estimator.predict(X_test).reshape(-1)\n",
    "        weak_predictions.append(pred)\n",
    "    weak_predictions = np.array(weak_predictions)\n",
    "\n",
    "    if weak_predictions.shape != (boosted_model.n_estimators, X_test.shape[0]):\n",
    "        print(f\"Incorrect shape for weak learner predictions.\\nExpected: {(boosted_model.n_estimators, X_test.shape[0])}\\n\"\n",
    "              f\"Actual: {weak_predictions.shape}\")\n",
    "    else:\n",
    "        print(\"Weak learner predictions shape is correct.\")\n",
    "        \n",
    "    \n",
    "\n",
    "    # Edge Case 2: All Inputs the Same\n",
    "    print(\"\\n---------------------------------\")\n",
    "    print(\"\\nTesting with identical input values.\")\n",
    "    X_test_identical = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]])\n",
    "    Y_test_identical = np.array([0, 0, 1, 1, 0])\n",
    "    boosted_model.train(X_test_identical, Y_test_identical)\n",
    "    computed_loss_identical = boosted_model.loss(X_test_identical, Y_test_identical)\n",
    "    if computed_loss_identical == pytest.approx(0.32526973, .01):\n",
    "        print(\"Model computed loss is correct.\")\n",
    "    else:\n",
    "        print(\"Model computed loss is NOT correct.\")\n",
    "    \n",
    "    # Estimator Weights Normalization\n",
    "    print(\"\\nTesting estimator weights normalization.\")\n",
    "    weight_sum = np.sum(boosted_model.estimator_weights)\n",
    "    if not np.isclose(weight_sum, 1.0, atol=1e-6):\n",
    "        print(f\"Estimator weights are not normalized.\\nSum of weights: {weight_sum}\")\n",
    "    else:\n",
    "        print(\"Estimator weights are normalized correctly.\")\n",
    "\n",
    "    # Individual Estimator Predictions\n",
    "    print(\"\\nTesting individual estimator predictions.\")\n",
    "    weak_predictions = []\n",
    "    for estimator in boosted_model.estimators:\n",
    "        pred = estimator.predict(X_test).reshape(-1)\n",
    "        weak_predictions.append(pred)\n",
    "    weak_predictions = np.array(weak_predictions)\n",
    "\n",
    "    if weak_predictions.shape != (boosted_model.n_estimators, X_test.shape[0]):\n",
    "        print(f\"Incorrect shape for weak learner predictions.\\nExpected: {(boosted_model.n_estimators, X_test.shape[0])}\\n\"\n",
    "              f\"Actual: {weak_predictions.shape}\")\n",
    "    else:\n",
    "        print(\"Weak learner predictions shape is correct.\")    \n",
    "    \n",
    "\n",
    "    # Edge Case 3: All Labels Same\n",
    "    print(\"\\n---------------------------------\")\n",
    "    print(\"\\nTesting with all labels being the same.\")\n",
    "    X_test_labels_same = np.array([[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3], [4, 4, 4]])\n",
    "    Y_test_labels_same = np.array([1, 1, 1, 1, 1])  # All labels are 1\n",
    "    boosted_model.train(X_test_labels_same, Y_test_labels_same)\n",
    "    computed_loss_labels_same = boosted_model.loss(X_test_labels_same, Y_test_labels_same)\n",
    "    if computed_loss_labels_same == pytest.approx(0.34004895, .01):\n",
    "        print(\"Model computed loss is correct.\")\n",
    "    else:\n",
    "        print(\"Model computed loss is NOT correct.\")\n",
    "        \n",
    "    # Estimator Weights Normalization\n",
    "    print(\"\\nTesting estimator weights normalization.\")\n",
    "    weight_sum = np.sum(boosted_model.estimator_weights)\n",
    "    if not np.isclose(weight_sum, 1.0, atol=1e-6):\n",
    "        print(f\"Estimator weights are not normalized.\\nSum of weights: {weight_sum}\")\n",
    "    else:\n",
    "        print(\"Estimator weights are normalized correctly.\")\n",
    "\n",
    "    # Individual Estimator Predictions\n",
    "    print(\"\\nTesting individual estimator predictions.\")\n",
    "    weak_predictions = []\n",
    "    for estimator in boosted_model.estimators:\n",
    "        pred = estimator.predict(X_test).reshape(-1)\n",
    "        weak_predictions.append(pred)\n",
    "    weak_predictions = np.array(weak_predictions)\n",
    "\n",
    "    if weak_predictions.shape != (boosted_model.n_estimators, X_test.shape[0]):\n",
    "        print(f\"Incorrect shape for weak learner predictions.\\nExpected: {(boosted_model.n_estimators, X_test.shape[0])}\\n\"\n",
    "              f\"Actual: {weak_predictions.shape}\")\n",
    "    else:\n",
    "        print(\"Weak learner predictions shape is correct.\")  \n",
    "        \n",
    "\n",
    "\n",
    "    # Edge Case 4: High-Dimensional Input\n",
    "    print(\"\\n---------------------------------\")\n",
    "    print(\"\\nTesting with high-dimensional input.\")\n",
    "    X_test_high_dim = np.random.rand(5, 50)  # 5 samples, 50 features\n",
    "    Y_test_high_dim = np.array([0, 1, 0, 1, 0])\n",
    "    boosted_model.train(X_test_high_dim, Y_test_high_dim)\n",
    "    computed_loss_high_dim = boosted_model.loss(X_test_high_dim, Y_test_high_dim)\n",
    "    if np.isclose(computed_loss_high_dim, 0.34004895, atol=1e-6):\n",
    "        print(\"Model computed loss is correct.\")\n",
    "    else:\n",
    "        print(\"Model computed loss is NOT correct.\")\n",
    "\n",
    "    # Estimator Weights Normalization\n",
    "    print(\"\\nTesting estimator weights normalization.\")\n",
    "    weight_sum = np.sum(boosted_model.estimator_weights)\n",
    "    if not np.isclose(weight_sum, 1.0, atol=1e-6):\n",
    "        print(f\"Estimator weights are not normalized.\\nSum of weights: {weight_sum}\")\n",
    "    else:\n",
    "        print(\"Estimator weights are normalized correctly.\")\n",
    "\n",
    "    # Individual Estimator Predictions\n",
    "    print(\"\\nTesting individual estimator predictions.\")\n",
    "    weak_predictions = []\n",
    "    for estimator in boosted_model.estimators:\n",
    "        pred = estimator.predict(X_test_high_dim).reshape(-1)\n",
    "        weak_predictions.append(pred)\n",
    "    weak_predictions = np.array(weak_predictions)\n",
    "\n",
    "    if weak_predictions.shape != (boosted_model.n_estimators, X_test_high_dim.shape[0]):\n",
    "        print(f\"Incorrect shape for weak learner predictions.\\nExpected: {(boosted_model.n_estimators, X_test_high_dim.shape[0])}\\n\"\n",
    "            f\"Actual: {weak_predictions.shape}\")\n",
    "    else:\n",
    "        print(\"Weak learner predictions shape is correct.\")\n",
    "\n",
    "    # Edge Case 5: Very Large Dataset\n",
    "    print(\"\\n---------------------------------\")\n",
    "    print(\"\\nTesting with a very large dataset.\")\n",
    "    X_test_large = np.random.rand(10000, 10)  # 10,000 samples, 10 features\n",
    "    Y_test_large = np.random.randint(0, 2, size=10000)\n",
    "    boosted_model.train(X_test_large, Y_test_large)\n",
    "    computed_loss_large = boosted_model.loss(X_test_large, Y_test_large)\n",
    "    if np.isclose(computed_loss_large, 0.263257448, atol=1e-6):\n",
    "        print(\"Model computed loss is correct.\")\n",
    "    else:\n",
    "        print(\"Model computed loss is NOT correct.\")\n",
    "\n",
    "    # Estimator Weights Normalization\n",
    "    print(\"\\nTesting estimator weights normalization.\")\n",
    "    weight_sum = np.sum(boosted_model.estimator_weights)\n",
    "    if not np.isclose(weight_sum, 1.0, atol=1e-6):\n",
    "        print(f\"Estimator weights are not normalized.\\nSum of weights: {weight_sum}\")\n",
    "    else:\n",
    "        print(\"Estimator weights are normalized correctly.\")\n",
    "\n",
    "    # Individual Estimator Predictions\n",
    "    print(\"\\nTesting individual estimator predictions.\")\n",
    "    weak_predictions = []\n",
    "    for estimator in boosted_model.estimators:\n",
    "        pred = estimator.predict(X_test_large).reshape(-1)\n",
    "        weak_predictions.append(pred)\n",
    "    weak_predictions = np.array(weak_predictions)\n",
    "\n",
    "    if weak_predictions.shape != (boosted_model.n_estimators, X_test_large.shape[0]):\n",
    "        print(f\"Incorrect shape for weak learner predictions.\\nExpected: {(boosted_model.n_estimators, X_test_large.shape[0])}\\n\"\n",
    "            f\"Actual: {weak_predictions.shape}\")\n",
    "    else:\n",
    "        print(\"Weak learner predictions shape is correct.\")\n",
    "\n",
    "    # Edge Case 6: Edge Inputs (Zeros and Ones)\n",
    "    print(\"\\n---------------------------------\")\n",
    "    print(\"\\nTesting with edge inputs (all zeros and ones).\")\n",
    "    X_test_edges = np.array([[0, 0, 0], [1, 1, 1], [0, 1, 0], [1, 0, 1], [1, 1, 0]])\n",
    "    Y_test_edges = np.array([0, 1, 0, 1, 0])\n",
    "    boosted_model.train(X_test_edges, Y_test_edges)\n",
    "    computed_loss_edges = boosted_model.loss(X_test_edges, Y_test_edges)\n",
    "    if np.isclose(computed_loss_edges, 0.10650355, atol=1e-6):\n",
    "        print(\"Model computed loss is correct.\")\n",
    "    else:\n",
    "        print(\"Model computed loss is NOT correct.\")\n",
    "\n",
    "    # Estimator Weights Normalization\n",
    "    print(\"\\nTesting estimator weights normalization.\")\n",
    "    weight_sum = np.sum(boosted_model.estimator_weights)\n",
    "    if not np.isclose(weight_sum, 1.0, atol=1e-6):\n",
    "        print(f\"Estimator weights are not normalized.\\nSum of weights: {weight_sum}\")\n",
    "    else:\n",
    "        print(\"Estimator weights are normalized correctly.\")\n",
    "\n",
    "    # Individual Estimator Predictions\n",
    "    print(\"\\nTesting individual estimator predictions.\")\n",
    "    weak_predictions = []\n",
    "    for estimator in boosted_model.estimators:\n",
    "        pred = estimator.predict(X_test_edges).reshape(-1)\n",
    "        weak_predictions.append(pred)\n",
    "    weak_predictions = np.array(weak_predictions)\n",
    "\n",
    "    if weak_predictions.shape != (boosted_model.n_estimators, X_test_edges.shape[0]):\n",
    "        print(f\"Incorrect shape for weak learner predictions.\\nExpected: {(boosted_model.n_estimators, X_test_edges.shape[0])}\\n\"\n",
    "            f\"Actual: {weak_predictions.shape}\")\n",
    "    else:\n",
    "        print(\"Weak learner predictions shape is correct.\")\n",
    "\n",
    "test_Boosted_NN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show that it can be reproduced by sklearn's AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running models on ../data/wine.txt dataset\n",
      "----- Our Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5752329902177458\n",
      "Average Testing Loss: 0.5615628155504526\n",
      "----- sklearn Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5747030955673881\n",
      "Average Testing Loss: 0.5657154893148305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.5752329902177458),\n",
       " np.float64(0.5615628155504526),\n",
       " np.float64(0.5747030955673881),\n",
       " np.float64(0.5657154893148305),\n",
       " np.float64(0.7845845577055516),\n",
       " np.float64(0.782960316293052))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os \n",
    "\n",
    "def test_sklearn(dataset, test_size=0.2):\n",
    "    '''\n",
    "        Tests OneLayerNN, Boost on a given dataset.\n",
    "        :param dataset The path to the dataset\n",
    "        :return None\n",
    "    '''\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(dataset):\n",
    "        print('The file {} does not exist'.format(dataset))\n",
    "        exit()\n",
    "\n",
    "    # Load in the dataset\n",
    "    data = np.loadtxt(dataset, skiprows = 1)\n",
    "    X, Y = data[:, 1:], data[:, 0]\n",
    "\n",
    "    # Normalize the features\n",
    "    X = (X-np.mean(X, axis=0))/np.std(X, axis=0)\n",
    "    Y = Y \n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size)\n",
    "    print('Running models on {} dataset'.format(dataset))\n",
    " \n",
    "\n",
    "    # Add a bias\n",
    "    X_train_b = np.append(X_train, np.ones((len(X_train), 1)), axis=1)\n",
    "    X_test_b = np.append(X_test, np.ones((len(X_test), 1)), axis=1)\n",
    "\n",
    "    print('----- Our Boosted Network (Our NN) -----')\n",
    "    n_estimators = 25\n",
    "    learning = 0.5\n",
    "\n",
    "    model = Boosted_Model(n_estimators=n_estimators, learning_rate=learning)\n",
    "    model.train(X_train_b, Y_train)\n",
    "\n",
    "    our_train_loss = (model.loss(X_train_b, Y_train))\n",
    "    our_test_loss = (model.loss(X_test_b, Y_test))\n",
    "  \n",
    "    print('Average Training Loss:', our_train_loss)\n",
    "    print('Average Testing Loss:', our_test_loss)\n",
    "\n",
    "    #### sklearn Boosted with our NN ######\n",
    "    print('----- sklearn Boosted Network (Our NN) -----')\n",
    "\n",
    "    model = AdaBoostRegressor(OneLayerNN(), n_estimators=n_estimators, learning_rate=learning)\n",
    "    \n",
    "    model.fit(X_train_b, Y_train)\n",
    "\n",
    "    sklearn_train_loss = mean_squared_error(model.predict(X_train_b), Y_train)\n",
    "    sklearn_test_loss = mean_squared_error(model.predict(X_test_b), Y_test)\n",
    "  \n",
    "    print('Average Training Loss:', sklearn_train_loss)\n",
    "    print('Average Testing Loss:', sklearn_test_loss)\n",
    "\n",
    "    baseline_train = mean_squared_error(np.ones(Y_train.shape) * np.mean(Y_train), Y_train)\n",
    "    baseline_test = mean_squared_error(np.ones(Y_test.shape) * np.mean(Y_train), Y_test)\n",
    "    \n",
    "    return our_train_loss, our_test_loss, sklearn_train_loss, sklearn_test_loss, baseline_train, baseline_test\n",
    "\n",
    "test_sklearn('../data/wine.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running models on ../data/wine.txt dataset\n",
      "----- Our Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5682574919322486\n",
      "Average Testing Loss: 0.6011007771395985\n",
      "----- sklearn Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5638947713193695\n",
      "Average Testing Loss: 0.5922916349767658\n",
      "Running models on ../data/wine.txt dataset\n",
      "----- Our Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5671654416189561\n",
      "Average Testing Loss: 0.6000681051614906\n",
      "----- sklearn Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.566011293727811\n",
      "Average Testing Loss: 0.5946491363651013\n",
      "Running models on ../data/wine.txt dataset\n",
      "----- Our Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5772881725799439\n",
      "Average Testing Loss: 0.551295020360692\n",
      "----- sklearn Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.577574179054741\n",
      "Average Testing Loss: 0.5471304103047739\n",
      "Running models on ../data/wine.txt dataset\n",
      "----- Our Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5717846561226821\n",
      "Average Testing Loss: 0.560669116463898\n",
      "----- sklearn Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5748294374115468\n",
      "Average Testing Loss: 0.5698265675777416\n",
      "Running models on ../data/wine.txt dataset\n",
      "----- Our Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5728187621543281\n",
      "Average Testing Loss: 0.5719122498960694\n",
      "----- sklearn Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5698564749505625\n",
      "Average Testing Loss: 0.555436725460365\n",
      "Running models on ../data/wine.txt dataset\n",
      "----- Our Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5755118886662816\n",
      "Average Testing Loss: 0.5594658810289141\n",
      "----- sklearn Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5768110389359689\n",
      "Average Testing Loss: 0.5602821422466827\n",
      "Running models on ../data/wine.txt dataset\n",
      "----- Our Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5572847999793845\n",
      "Average Testing Loss: 0.6381429996203657\n",
      "----- sklearn Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5514164908845389\n",
      "Average Testing Loss: 0.6390300380403038\n",
      "Running models on ../data/wine.txt dataset\n",
      "----- Our Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5828823533061807\n",
      "Average Testing Loss: 0.539013224512257\n",
      "----- sklearn Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5839043783802255\n",
      "Average Testing Loss: 0.5344629767086984\n",
      "Running models on ../data/wine.txt dataset\n",
      "----- Our Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5674027857863533\n",
      "Average Testing Loss: 0.6028377216033031\n",
      "----- sklearn Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5677813015379903\n",
      "Average Testing Loss: 0.5896030734872949\n",
      "Running models on ../data/wine.txt dataset\n",
      "----- Our Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5722170666334819\n",
      "Average Testing Loss: 0.5679727199733051\n",
      "----- sklearn Boosted Network (Our NN) -----\n",
      "Average Training Loss: 0.5691079500923687\n",
      "Average Testing Loss: 0.5663230217500441\n"
     ]
    }
   ],
   "source": [
    "# Make a plot over 10 random seeds\n",
    "import matplotlib.pyplot as plt\n",
    "num_seeds = 10\n",
    "\n",
    "our_train_losses, our_test_losses, sklearn_train_losses, sklearn_test_losses, bs_trains, bs_tests = [], [], [], [], [], []\n",
    "\n",
    "for i in range(num_seeds):\n",
    "    our_train_loss, our_test_loss, sklearn_train_loss, sklearn_test_loss, bs_train, bs_test = test_sklearn('../data/wine.txt')\n",
    "    our_train_losses.append(our_train_loss)\n",
    "    our_test_losses.append(our_test_loss)\n",
    "    sklearn_train_losses.append(sklearn_train_loss)\n",
    "    sklearn_test_losses.append(sklearn_test_loss)\n",
    "    bs_trains.append(bs_train)\n",
    "    bs_tests.append(bs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = [our_train_losses, our_test_losses, sklearn_train_losses, sklearn_test_losses]\n",
    "labels = [\"Our Train Loss\", \"Our Test Loss\", \"Sklearn Train Loss\", \"Sklearn Test Loss\"]\n",
    "losses_bs = [our_train_losses, our_test_losses, sklearn_train_losses, sklearn_test_losses, bs_trains, bs_tests]\n",
    "labels_bs = [\"Our Train Loss\", \"Our Test Loss\", \"Sklearn Train Loss\", \"Sklearn Test Loss\", \"Baseline Train Loss\", \"Baseline Test Loss\"]\n",
    "\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.boxplot(losses,tick_labels=labels,vert=False)\n",
    "plt.title(\"Our Boosting Algorithim Vs. Sklearns using our Weak Learner\")\n",
    "plt.xlabel('Loss (MSE)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.boxplot(losses_bs,tick_labels=labels_bs,vert=False)\n",
    "plt.title(\"Our Boosting Algorithim Vs. Sklearns using our Weak Learner\")\n",
    "plt.xlabel('Loss (MSE)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc Code (Not on Rubric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def test_models_with_hyperparameters(dataset, test_size=0.2, n_estimators_list=[10, 50, 100], learning_rate_list=[0.01, 0.1, 0.5]):\n",
    "    '''\n",
    "        Tests OneLayerNN and Boosted_NN with varying hyperparameters.\n",
    "        :param dataset: The path to the dataset\n",
    "        :param test_size: Fraction of the dataset to be used for testing\n",
    "        :param n_estimators_list: List of values for the number of estimators\n",
    "        :param learning_rate_list: List of values for the learning rate\n",
    "        :return: None\n",
    "    '''\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(dataset):\n",
    "        print(f'The file {dataset} does not exist')\n",
    "        return\n",
    "\n",
    "    # Load in the dataset\n",
    "    data = np.loadtxt(dataset, skiprows=1)\n",
    "    X, Y = data[:, 1:], data[:, 0]\n",
    "\n",
    "    # Normalize the features\n",
    "    X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "    # Split dataset\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Add a bias term to the features\n",
    "    X_train_b = np.append(X_train, np.ones((len(X_train), 1)), axis=1)\n",
    "    X_test_b = np.append(X_test, np.ones((len(X_test), 1)), axis=1)\n",
    "\n",
    "    # Results storage for plotting\n",
    "    nn_train_losses = []\n",
    "    nn_test_losses = []\n",
    "    boosted_train_losses = {}\n",
    "    boosted_test_losses = {}\n",
    "\n",
    "    #### 1-Layer NN ######\n",
    "    print('----- 1-Layer NN -----')\n",
    "    nnmodel = OneLayerNN()\n",
    "    nnmodel.fit(X_train_b, Y_train, np.ones(X_train_b.shape[0]))\n",
    "    nn_train_loss = nnmodel.average_loss(X_train_b, Y_train, np.ones(X_train_b.shape[0]))\n",
    "    nn_test_loss = nnmodel.average_loss(X_test_b, Y_test, np.ones(X_test_b.shape[0]))\n",
    "    nn_train_losses.append(nn_train_loss)\n",
    "    nn_test_losses.append(nn_test_loss)\n",
    "    # print('Average Training Loss (1-Layer NN):', nn_train_loss)\n",
    "    # print('Average Testing Loss (1-Layer NN):', nn_test_loss)\n",
    "\n",
    "    #### Boosted Neural Networks ######\n",
    "    print('----- Boosted Neural Networks -----')\n",
    "    for n_estimators in n_estimators_list:\n",
    "        for learning_rate in learning_rate_list:\n",
    "            print(f'Testing Boosted_NN with n_estimators={n_estimators}, learning_rate={learning_rate}')\n",
    "            model = Boosted_Model(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "            model.train(X_train_b, Y_train)\n",
    "            train_loss = model.loss(X_train_b, Y_train)\n",
    "            test_loss = model.loss(X_test_b, Y_test)\n",
    "            print(f'Training Loss: {train_loss}, Testing Loss: {test_loss}')\n",
    "\n",
    "            # Store results\n",
    "            boosted_train_losses[(n_estimators, learning_rate)] = train_loss\n",
    "            boosted_test_losses[(n_estimators, learning_rate)] = test_loss\n",
    "\n",
    "    # Plot the results\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot for Boosted NN\n",
    "    for n_estimators in n_estimators_list:\n",
    "        train_losses = [boosted_train_losses[(n_estimators, lr)] for lr in learning_rate_list]\n",
    "        test_losses = [boosted_test_losses[(n_estimators, lr)] for lr in learning_rate_list]\n",
    "        \n",
    "        ax.plot(learning_rate_list, train_losses, marker='o', label=f'Train Loss (n_estimators={n_estimators})')\n",
    "        ax.plot(learning_rate_list, test_losses, marker='x', label=f'Test Loss (n_estimators={n_estimators})', linestyle='--')\n",
    "    \n",
    "    ax.set_title('Boosted NN Loss vs Learning Rate')\n",
    "    ax.set_xlabel('Learning Rate')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_xscale('log')  # Keep the log scale for learning rates\n",
    "    ax.set_xticks(learning_rate_list)  # Explicitly set the ticks\n",
    "    ax.get_xaxis().set_major_formatter(plt.ScalarFormatter())  # Ensure proper formatting of tick labels\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "test_models_with_hyperparameters('../data/wine.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Freund, Y. and Schapire, R.E. (1997) 'A Decision-Theoretic generalization of On-Line learning and an application to boosting,' Journal of Computer and System Sciences, 55(1), pp. 119–139. https://doi.org/10.1006/jcss.1997.1504.\n",
    "\n",
    "[2] Drucker, Harris. (1997). Improving Regressors using boosting Techniques. Proceedings of the 14th International Conference on Machine Learning. https://www.researchgate.net/publication/2424244_Improving_Regressors_Using_Boosting_Techniques\n",
    "\n",
    "[3] UCI Machine Learning Repository (2009). https://archive.ics.uci.edu/dataset/186/wine+quality."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "y7jqYzqTDwBc"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "data2060_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
